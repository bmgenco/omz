---
title: "figure_4_Bud_export_flux"
author: "Brandon M. Genco"
date: "10/9/2022"
output: html_document
---

# Setup  
Packages, Directories, 

## dynamic directories

```{r setup}
rm(list=ls())
# relative directories
robj<-"r_objects"
fig<-"../../figures"
gis_data<-"../../data/gis_data"
data_d<-"../../data/2018_data"

sst_data<-"../../data/POC_Flux_data_sets/annual_vgpm_modis_sst_netcdf"
chl_data<-"../../data/POC_Flux_data_sets/annual_vgpm_modis_chl_netcdf"


knitr::opts_chunk$set(echo =FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

## packages and working directory

Installed custom hurdat package using r markdown menu
* download  tar from archive as no longer maintained on cran repository
* https://cran.r-project.org/src/contrib/Archive/HURDAT/
+ include as git submodule instead

```{r}
wd<-getwd()

f.ipak <- function(pkg){
  # loads packages, quietly, given by a vector of package names e.g., pkg<-c("ggplot", "tidyverse")
  # will install  packages listed , and their dependencies, if needed.
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE, quiet=T, verbose = F)
  sapply(pkg, require, character.only = TRUE, quietly = FALSE, warn.conflicts=F)
}


packages<-c("sp", "rgdal",  "rgeos", "raster", "readr", "tidyverse", "lubridate",  "ggthemes",  "sf", "cmocean", "ncdf4", "RNetCDF",  "plot3D", "tidync", "devtools", "stars", "ncmeta", "maps", "oce", "data.table", "fasterize", "RStoolbox", "scales", "purrr", "HURDAT", "ggpattern")

# "HURDAT",

f.ipak(packages)
# lapply(packages, require, character.only = TRUE)
# rm(f.ipak, packages)
print(paste0("Current Working Directory is ", getwd()))

```


# Functions

```{r}
f.grid_square_area2<-function(x) {
  x.area<-vector(mode="numeric", length = nrow(x)) 
  
  for(i in 1:length(x.area)){
    bbox<-st_bbox(x[[2]][[i]])
    box<-vector(mode="numeric", length=4)
    names(box)<-c("xmin","ymin","ymax", "xmax")
    box$ymin<-round(bbox$ymin[[1]]-(5/120),3)
    box$ymax<-round(bbox$ymax[[1]]+(5/120),3)
    box$xmin<-round(bbox$xmin[[1]] +-(5/120),3)
    box$xmax<-round(bbox$xmax[[1]] +(5/120),3)
    x.area[i]<- rgeos::bbox2SP(n = box$ymax[[1]], s = box$ymin[[1]], w = box$xmin[[1]], e = box$xmax[[1]],
                               proj4string = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")) %>% st_as_sf(.,) %>% st_area(.,) %>% round(., -1)
  }
  sum_grid_area<-sum(x.area)
  x$value<-x.area
  y<-vector(mode = "list", length=2)
  names(y)<-c("grid_area", "sum_grid_area")
  y$grid_area<-x
  y$sum_grid_area<-sum_grid_area
  
  return(y)}

f.sst_data_nc<-function(z){
  
  sst_integrated<-as.data.frame(matrix(ncol = 7, nrow =length(files)))
  names(sst_integrated)<-c("date",  "SST_mean (area weighted)", "SST_mean (basic)", "SST_median", "SST_variance", "window_area (m^2)", "sum_grid_area (m^2)")
  
  for(i in 1:length(files)){
    file<-files[i]
    t<-tidync(file)%>% hyper_filter(lat = lat >= min(z$lat) & lat <= max(z$lat), lon = lon>= min(z$lon) & lon<= max(z$lon)) %>% hyper_tibble()
    # t$sst[t$sst == -9999] <- NA
    x<-t$sst
    x.sf<-t%>%st_as_sf(., coords = c("lon", "lat" ), crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")
    
    bbox<-st_bbox(x.sf)
    box<-vector(mode="numeric", length=4)
    names(box)<-c("xmin","ymin","ymax", "xmax")
    box$ymin<-round(bbox$ymin[[1]]-(5/120),3)
    box$ymax<-round(bbox$ymax[[1]]+(5/120),3)
    box$xmin<-round(bbox$xmin[[1]] +-(5/120),3)
    box$xmax<-round(bbox$xmax[[1]] +(5/120),3)
    
    area <- rgeos::bbox2SP(n = box$ymax[[1]], s = box$ymin[[1]], w = box$xmin[[1]], e = box$xmax[[1]],
                           proj4string = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")) %>% st_as_sf(.,) %>% st_area(.,)
    rm(box, bbox)
    
    t<-str_split(file, '\\.')
    t<-t[[1]][2]
    t<-str_split(t, "")
    y<-c(t[[1]][1:4])%>% toString(.) %>% gsub(",","",.) %>% gsub(" ","",.)   
    yd<-c(t[[1]][5:7])%>% toString(.) %>% gsub(",","",.) %>% gsub(" ","",.)
    origin<-toString(c(y,"-01-01")) %>% gsub(",","",.) %>% gsub(" ","",.)
    
    
    names(x.sf)<-c("value", "geometry")
    y<-f.grid_square_area2(x.sf)
    q<-y$grid_area$value/y$sum_grid_area
    wa<-sum(q*x)
   
    sst_integrated[i,1]<-as.character(as.Date(as.numeric(yd), origin=origin)) # date  
    sst_integrated[i,2]<-wa
    sst_integrated[i,3]<-mean(x) # vgpm_median
    sst_integrated[i,4]<-median(x) # vgpm_mean
    sst_integrated[i,5]<-var(x) # vgpm_variance
    sst_integrated[i,6]<-as.numeric(area) # window_area (m^2) 
    sst_integrated[i,7]<-y$sum_grid_area # sum_grid_area (m^2)
    
  }
  
  
  # n<-names(vgpm_integrated)
  # vgpm_integrated<-dplyr::select(vgpm_integrated, n[1], n[12], n[13], n[6], n[7], n[9], n[10], n[8],n[2], n[3],  n[11], n[4], n[5] )
  
  return(sst_integrated)}

f.chl_data_nc<-function(z){
  
  chl_integrated<-as.data.frame(matrix(ncol = 7, nrow =length(files)))
  names(chl_integrated)<-c("date",  "chl_mean (area weighted)", "chl_mean (basic)", "chl_median", "chl_variance", "window_area (m^2)", "sum_grid_area (m^2)")
  
  for(i in 1:length(files)){
    file<-files[i]
    t<-tidync(file)%>% hyper_filter(lat = lat >= min(z$lat) & lat <= max(z$lat), lon = lon>= min(z$lon) & lon<= max(z$lon)) %>% hyper_tibble()
    # t$sst[t$sst == -9999] <- NA
    x<-t$chl
    x.sf<-t%>%st_as_sf(., coords = c("lon", "lat" ), crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")
    
    bbox<-st_bbox(x.sf)
    box<-vector(mode="numeric", length=4)
    names(box)<-c("xmin","ymin","ymax", "xmax")
    box$ymin<-round(bbox$ymin[[1]]-(5/120),3)
    box$ymax<-round(bbox$ymax[[1]]+(5/120),3)
    box$xmin<-round(bbox$xmin[[1]] +-(5/120),3)
    box$xmax<-round(bbox$xmax[[1]] +(5/120),3)
    
    area <- rgeos::bbox2SP(n = box$ymax[[1]], s = box$ymin[[1]], w = box$xmin[[1]], e = box$xmax[[1]],
                           proj4string = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")) %>% st_as_sf(.,) %>% st_area(.,)
    rm(box, bbox)
    
    t<-str_split(file, '\\.')
    t<-t[[1]][2]
    t<-str_split(t, "")
    y<-c(t[[1]][1:4])%>% toString(.) %>% gsub(",","",.) %>% gsub(" ","",.)   
    yd<-c(t[[1]][5:7])%>% toString(.) %>% gsub(",","",.) %>% gsub(" ","",.)
    origin<-toString(c(y,"-01-01")) %>% gsub(",","",.) %>% gsub(" ","",.)
    
    
    names(x.sf)<-c("value", "geometry")
    y<-f.grid_square_area2(x.sf)
    q<-y$grid_area$value/y$sum_grid_area
    wa<-sum(q*x)
    
    chl_integrated[i,1]<-as.character(as.Date(as.numeric(yd), origin=origin)) # date  
    chl_integrated[i,2]<-wa
    chl_integrated[i,3]<-mean(x) # vgpm_median
    chl_integrated[i,4]<-median(x) # vgpm_mean
    chl_integrated[i,5]<-var(x) # vgpm_variance
    chl_integrated[i,6]<-as.numeric(area) # window_area (m^2) 
    chl_integrated[i,7]<-y$sum_grid_area # sum_grid_area (m^2)
    
  }
  
  
  # n<-names(vgpm_integrated)
  # vgpm_integrated<-dplyr::select(vgpm_integrated, n[1], n[12], n[13], n[6], n[7], n[9], n[10], n[8],n[2], n[3],  n[11], n[4], n[5] )
  
  return(chl_integrated)}
```

# loading Important objects and data sets & intial data wranglaing

## funtion variables
-from previous scripts

```{r}
setwd(wd)
setwd(robj)


load("20220201_temp_workspace.RData")
rm(m.coast, database)
```


## load basic hurdat

```{r}
setwd(wd)
setwd(robj)
# h<-get_hurdat(basin="EP")
# saveRDS(h, "hurdat.R")

h<-readRDS("hurdat.R")
h$DateTime<-with_tz(h$DateTime, tz="UTC")
```

## loading  coastal subsetting objects 
- see script "GRL_Main_Figures.Rmd"
```{r}
setwd(wd)
setwd(gis_data)
coastline<-st_read("./ne_50m_land/ne_50m_land.shp") 
# ocean<-st_read("./ne_50m_ocean/ne_50m_ocean.shp") 
cl<-st_crop(coastline, xmin=function_variables$h.lon_min, ymin=function_variables$h.lat_min, xmax=function_variables$h.lon_max, ymax=function_variables$h.lat_max)
rm(coastline)
 m.coast <- ggplot()+ geom_sf(data =cl, size=0.5)+ theme(axis.title.x=element_blank(), axis.title.y=element_blank())+
  theme_bw()+ theme(text = element_text(size =12)) 
# cl<-st_crop(coastline, xmin=-170, ymin=-20, xmax=-80, ymax=40) # change here based on desired figure size
# cl<-st_crop(coastline, xmin=min(h$Lon), ymin=min(h$Lat), xmax=max(h$Lon), ymax=max(h$Lat))
# oc<-st_crop(ocean, xmin=function_variables$h.lon_min, ymin=function_variables$h.lat_min, xmax=function_variables$h.lon_max, ymax=function_variables$h.lat_max)
 

```

## stations and buffer

```{r}
setwd(wd)
setwd(robj)

stations_positions_list<-readRDS("OC1806A_stations_positions_list.R")



st<-stations_positions_list[[3]][4,cbind(2,3)]
st<-sf::st_as_sf(st, coords =c("longitude", "latitude"),  crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")
flat<-sf::st_transform(st, "+proj=aeqd +lat_0=18.5005 +lon_0=-108.502" )

## radius in km for POC select
radii<-100000 
circle_3.5_200km<-sf::st_buffer(flat, dist=radii)%>%sf::st_transform(., "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")

## for selecting TC that intersect
radii<-2*radii 

circle_3.5_400km<-sf::st_buffer(flat, dist=radii)%>%sf::st_transform(., "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")

rm(flat, radii, st, stations_positions_list)


```

## loading POC
```{r}
setwd(wd)
setwd(robj)


data<-read_rds("vgpm_integrated_all_years_202200607.R")
x<-data$st3.5
rm(data)

window_area<-round((x$`window_area (m^2)`[1]*1e-6),0)
lab_total<-paste0("Station ", "3.5", ":", " Total Export Flux - ", window_area, " km^2 area")

x$date<-ymd(x$date)
x<-select(x, date, `mean_export_flux (mgC/m^2/day) for_window_area (total/sum_grid_area)`, `total_export_flux (mgC/day)`)
names(x)<-c("date", "avg", "ef")
x$ef<-x$ef/1000000

sst<-readRDS("st35_sst_modis.R")
z<-select(sst, date, `SST_mean (area weighted)`)
rm(sst)
names(z)<-c("date", "sst")
z$date<-ymd(z$date)


chl<-readRDS("st35_chl_modis.R")
y<-select(chl, date, 'chl_mean (area weighted)')
rm(chl)
names(y)<-c("date", "chl")
y$date<-ymd(y$date)

```


# TC slection

## spatial temporal subsetting
```{r}
bbox<-st_bbox(circle_3.5_200km)


g<-filter(h, DateTime >=date(min(x$date))-60) # save 'h' in order to adjust function variables if needed.
h.pts<- sf::st_as_sf(g, coords = c("Lon","Lat"), crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0") %>% 
sf::st_crop(., c(xmin=bbox$xmin[[1]], ymin=bbox$ymin[[1]], xmax=bbox$xmax[[1]], ymax=bbox$ymax[[1]])) #subset by user defined 
rm(g, bbox)
```

## split and recombine 200 km storms

```{r}

all<-h
t<-h.pts 
st_geometry(t)<-NULL
# t$ymin<--Inf
# t$ymax<-Inf
# t$DateTime<-as.Date(t$DateTime)
t$DateTime<-as_datetime(t$DateTime)

# unique(t$Status)
 
# see:  https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-atl-1851-2021.pdf
#"TS" tropical cyclone of tropical storm intensity (34-63 knots)
# "TD" Tropical cyclone of tropical depression intensity (< 34 knots)
# LO – A low that is neither a tropical cyclone, a subtropical cyclone, nor an extra tropical cyclone (of any intensity)
# DB – Disturbance (of any intensity)
# splits in individual storms to hurricanes and all else. If an individual storm was bot below and a hurricane and a hurricane in the subset it mark it as a hurricane

remove_200<-unique(t$Key)
 
h<-t%>% group_by(Key) %>% filter(any(Status== "HU"))
t<-t %>% subset(., !(Key %in% unique(h$Key)))%>% group_by(Key)

t<-group_split(t)
t<-lapply(t, as.data.frame)

h<-group_split(h)
h<-lapply(h, as.data.frame)

# need to convert above using to this-> https://stackoverflow.com/questions/29648907/using-geom-rect-for-time-series-shading-in-r

start<-vector(mode="character", length=length(h))
end<-vector(mode="character", length=length(h))
pres<-vector(mode="integer", length=length(h))
key<-vector(mode="character", length=length(h))
name<-vector(mode="character", length=length(h))
wind<-vector(mode="integer", length=length(h))

for(i in 1:length(h)){
  start[[i]]<-as.character(min(h[[i]]$DateTime))
  end[[i]]<-as.character(max(h[[i]]$DateTime))
  pres[[i]]<-median(h[[i]]$Pressure)
  
  
  # pres[[i]]<-min(h[[i]]$Pressure)
}

# h_rect<-data.frame(start=date(start), end=date(end), y1=-Inf, y2=pres)
h_rect<-data.frame(key=Key, name=Name, start=date(start), end=date(end), pressure=pres)


start<-vector(mode="character", length=length(t))
end<-vector(mode="character", length=length(t))
pres<-vector(mode="integer", length=length(t))

for(i in 1:length(t)){
  start[[i]]<-as.character(min(t[[i]]$DateTime))
  end[[i]]<-as.character(max(t[[i]]$DateTime))
  pres[[i]]<-median(t[[i]]$Pressure)
  #   
}

t_rect<-data.frame(start=date(start), end=date(end), y1=-Inf, y2=pres)
rm(t,h)


#standard atmospheric presures in millibars


```


## split and recombine 400 km storms only

```{r}
setwd(wd)
setwd(robj)
h<-all

radii<-100000 ## radius in km for POC select

radii<-2*radii ## for selecting TC that intersect

stations_positions_list<-readRDS("OC1806A_stations_positions_list.R")

st<-stations_positions_list[[3]][4,cbind(2,3)]
st<-sf::st_as_sf(st, coords =c("longitude", "latitude"),  crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")
flat<-sf::st_transform(st, "+proj=aeqd +lat_0=18.5005 +lon_0=-108.502" )
circle_3.5_400km<-sf::st_buffer(flat, dist=radii)%>%sf::st_transform(., "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")

bbox<-st_bbox(circle_3.5_400km)

# x<-filter(h, Status == "HU") %>% filter(., DateTime >=date(min(poc$date))-60) # save 'h' in order to adjust function variables if needed.
g<-filter(h, DateTime >=date(min(poc$date))-60) # save 'h' in order to adjust function variables if needed.
g<-h

h.pts<- sf::st_as_sf(g, coords = c("Lon","Lat"), crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0") %>% 
sf::st_crop(., c(xmin=bbox$xmin[[1]], ymin=bbox$ymin[[1]], xmax=bbox$xmax[[1]], ymax=bbox$ymax[[1]])) #subset by user defined 

# h.pts<-st_difference(h.pts, st_combine(st_geometry(cl))) # remove all points over land
rm(g, poc)

t_4<-h.pts 
st_geometry(t_4)<-NULL
t_4$ymin<--Inf
t_4$ymax<-Inf
# t$DateTime<-as.Date(t$DateTime)
t_4$DateTime<-as_datetime(t_4$DateTime)


#commneted out below. for paper statistics only
h_4<-t_4 %>% subset(., !(Key %in% remove_200))
h_4_all<-t_4

t_4<-t_4 %>% subset(., !(Key %in% remove_200))%>% group_by(Key)


t_4<-group_split(t_4)
t_4<-lapply(t_4, as.data.frame)

start<-vector(mode="character", length=length(t_4))
end<-vector(mode="character", length=length(t_4))
pres<-vector(mode="integer", length=length(t_4))

for(i in 1:length(t_4)){
  start[[i]]<-as.character(min(t_4[[i]]$DateTime))
  end[[i]]<-as.character(max(t_4[[i]]$DateTime))
  pres[[i]]<-median(t_4[[i]]$Pressure)
  #
}

t_4_rect<-data.frame(start=date(start), end=date(end), y1=-Inf, y2=pres)



```



