---
title: "export_flux_for mike"
output: html_document
date: '2022-10-28'
---
# Setup
## Directories and defaults
Use r proj file for relative directories
see: https://yihui.org/knitr/options/


```{r setup}
rm(list=ls())
# relative directories
robj<-"r_objects"
fig<-"../../figures"
gis_data<-"../../data/gis_data"
output<-"../../output"


knitr::opts_chunk$set(echo =FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

```

## packages and working directory

Installed custom hurdat package using r markdown menu
* download  tar from archive as no longer maintained on cran repository
* https://cran.r-project.org/src/contrib/Archive/HURDAT/
+ include as git submodule instead

```{r}
wd<-getwd()

f.ipak <- function(pkg){
  # loads packages, quietly, given by a vector of package names e.g., pkg<-c("ggplot", "tidyverse")
  # will install  packages listed , and their dependencies, if needed.
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE, quiet=T, verbose = F)
  sapply(pkg, require, character.only = TRUE, quietly = FALSE, warn.conflicts=F)
}

# packages<-c("stars", "gridExtra", "cowplot", "sf", "ggspatial","stringr","sp", "rgdal",  "rgeos", "raster","readr" ,"tidyverse", "ggplot2", "lubridate",  "ggthemes", "data.table", "reshape2", "RColorBrewer", "marmap", "extrafont", "oce", "MODIS", "measurements")  # set packages here
# tidyverse: is all of the following packages: ggplot2, dplyr, tidyr, readr, purr, tibble, sringr, & forcats.

# remotes::install_github("R-Finance/xtsExtra")

packages<-c("sp", "rgdal",  "rgeos", "raster", "readr", "tidyverse", "lubridate",  "ggthemes",  "sf", "cmocean", "ncdf4", "RNetCDF",  "plot3D", "tidync", "devtools", "stars", "ncmeta", "maps", "oce", "data.table", "fasterize", "RStoolbox", "scales", "purrr", "HURDAT", "ggpattern", "zoo", "xts", "dsa",  "tsibble", "feasts", "tsbox", "rsoi")

# "HURDAT",

f.ipak(packages)
# lapply(packages, require, character.only = TRUE)
# rm(f.ipak, packages)
print(paste0("Current Working Directory is ", getwd()))

```


# Functions

```{r}
f.anomaly<-function(c){
  m<-mean(c)
  n<-c-m
  return(n)
}
```

# Loading Data

## load basic hurdat

```{r}
setwd(wd)
setwd(robj)
h<-get_hurdat(basin="EP")
# saveRDS(h, "hurdat.R")
# h<-readRDS("hurdat.R")
h$DateTime<-force_tz(h$DateTime, tz="UTC")

```


## loading POC

```{r}
setwd(wd)
setwd(robj)

data<-read_rds("vgpm_integrated_all_years_202200607.R")
x<-data$st3.5
rm(data)

window_area<-round((x$`window_area (m^2)`[1]*1e-6),0)
lab_total<-paste0("Station ", "3.5", ":", " Total Export Flux - ", window_area, " km^2 area")

x$date<-ymd(x$date)
x<-select(x, date, `mean_export_flux (mgC/m^2/day) for_window_area (total/sum_grid_area)`, `total_export_flux (mgC/day)`)
names(x)<-c("date", "avg", "ef")
x$ef<-x$ef/1000000

sst<-readRDS("st35_sst_modis.R")
z<-select(sst, date, `SST_mean (area weighted)`)
rm(sst)
names(z)<-c("date", "sst")
z$date<-ymd(z$date)

chl<-readRDS("st35_chl_modis.R")
y<-select(chl, date, 'chl_mean (area weighted)')
rm(chl)
names(y)<-c("date", "chl")
y$date<-ymd(y$date)

```
here

### creat anomalies
```{r}
x$ef.a<-f.anomaly(x$ef)
x$avg.a<-f.anomaly(x$avg)

y$chl.a<-f.anomaly(y$chl)
z$sst.a<-f.anomaly(z$sst)

xnames<-c("date", "avg_EF_mgC_m2_day", "total_EF_mgC_day", "total_EF_anomaly_mgC_day", "avg_EF_anomaly_mgC_m2_day")
ynames<-c("date", "avg_CHL_mg_m3_day","avg_CHL_anomaly_mg_m3_day")
znames<-c("date", "avg_SST_C", "SST_anomaly_C")

names(x)<-xnames
names(y)<-ynames
names(z)<-znames

# conv<-3.944e+10
# 94.11872*conv

rm(xnames, ynames, znames)

x1<-full_join(y,z, by="date")%>% full_join(., x, by="date")
# missing_values<- x1[rowSums(is.na(x1)) > 0,] # a few misinf vlauers. see august 2020 for export flux
rm(x,y,z)

```


## filled and non-filled dataset

x1= non_filled

```{r}
start<-min(x1$date)
end<-max(x1$date)%>%+7
d<-data.frame(seq(ymd(start), ymd(end), b="days"), NA)
names(d)<-c("date", "remove")


x1[is.na(x1)]<--1 #save an values for later

x2<-full_join(d, x1, by="date") %>% select(., -remove) 
x2<-x2%>% fill(names(x2), .direction =  "down")
x2[x2==-1]<-NA
# rm(x1,d)

```

#@ spatil selection of storms

```{r}
# 
 # save_h<-h
# h<-save_h

h<-filter(h, DateTime >=date(min(x2$date))-60) 
h$date<-date(h$DateTime)
h<-select(h, date,Key, Name, Status, Pressure, Wind, Lon, Lat)

# distance<-100000 #200 km
distance<-200000 #400 km

setwd(wd)
setwd(robj)
stations_positions_list<-readRDS("OC1806A_stations_positions_list.R")
st<-stations_positions_list[[3]][4,cbind(2,3)]
st<-sf::st_as_sf(st, coords =c("longitude", "latitude"),  crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")
flat<-sf::st_transform(st, "+proj=aeqd +lat_0=18.5005 +lon_0=-108.502" )
circle_3.5<-sf::st_buffer(flat, dist=distance)%>%sf::st_transform(., "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")
bbox<-st_bbox(circle_3.5)

h.pts<- sf::st_as_sf(h, coords = c("Lon","Lat"), crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0") %>% 
sf::st_crop(., c(xmin=bbox$xmin[[1]], ymin=bbox$ymin[[1]], xmax=bbox$xmax[[1]], ymax=bbox$ymax[[1]])) #subset by user defined 

h<-st_set_geometry(h.pts, NULL)

# smotthing out multitiem points


new.h<-h %>% distinct(date, .keep_all = TRUE)


rm(circle_3.5, flat, stations_positions_list, st)

```

# non filledseanal signal

## alertanaive paackages

- ealry enddate removes missinf d data
- xts and ts

### xts
```{r}
# x1<-x1 %>% filter(date <= '2020-08-12') 
t<-(x1)%>%select(.,avg_CHL_mg_m3_day, avg_SST_C, avg_EF_mgC_m2_day )
names(t)<-c("CHL", "SST", "EF")
# t<-(x1)%>%select(., avg_SST_C)
t.d<-na.omit(x1)%>%select(., date)%>% .[,1]
#rename will break some code below

t<-xts(t, t.d)

```

### xts and ttibbel and feast

```{r}
# t<-ts_tsibble(t)

t.sst<-ts_tsibble(t) %>% filter(., id=="SST")
t.chl<-ts_tsibble(t) %>% filter(., id=="CHL")
t.ef<-ts_tsibble(t) %>% filter(., id=="EF")

trends<-ts_trend(t)

trend.sst<-ts_trend(t.sst)
trend.chl<-ts_trend(t.chl)
trend.ef<-ts_trend(t.ef)

# autoplot(trend.sst, col="red")
# autoplot(trend.chl, col="green")
# autoplot(trend.ef, col="black")

# plot.sst<-ts_plot(
#   `Raw series` = t.sst,
#   `Loess trend` = ts_trend(t.sst),
#   title = "Average SST",
#   subtitle = "for 200 km circle")
# 
# 
# plot.chl<-ts_plot(
#   "8-day data" = t.chl,
#   "Loess trend" = ts_trend(t.chl),
#   title = " Mean CHL_mg/m3/day",
#   subtitle = "for 200 km circle")
# 
# plot.ef<-ts_plot(
#   "8-day data" = t.ef,
#   "Loess trend" = ts_trend(t.ef),
#   title = "Mean export flux (mgC/m^2/day)",
#   subtitle = "for 200 km circle")

## ggplot options

p1<-ts_ggplot(t.chl, ts_trend(t.chl))+scale_color_manual(values = c("darkgreen", "purple"), labels=c("Mean CHL [mg/m3/day]", "Loews Trend"))+ theme_tsbox()


p2<-ts_ggplot(t.sst, ts_trend(t.sst))+scale_color_manual(values = c("red", "purple"), labels=c("Mean SST (Â°C)", "Loews Trend"))+ theme_tsbox()



p3<-ts_ggplot(t.ef, ts_trend(t.ef))+scale_color_manual(values = c("black", "purple"), labels=c("Mean Export Flux (mgC/m^2/day)", "Loews Trend"))+ theme_tsbox()





## test

s<-spectrum(t.sst)
f.sst<-fft(t.sst%)

# stuff that dpes wqorkk.

test<-t %>% model(stl = STL(value))

test<-tidy_fft(t$value)


test2<-ts_decompose(t)

test<-ts_trend(t)


test<-decompose(t)

```


# matching ONI index to trend

```{r}
oni<-download_oni()

oni<-oni%>% filter()
t.oni<-xts(oni$ONI, oni$Date)


```



### xts and ts
requres t as xts object
```{r}
# seems like ther should be an easri way..



remove(t.d)
periodicity(t$avg_SST_C)

# weekly hack

ts.sst<-ts(x1$avg_SST_C, frequency=52, start=c(2002, 07))
ts.chl<-ts(x1$avg_CHL_mg_m3_day, frequency=52, start=c(2002, 07))


d.sst<-decompose(ts.sst, type = "multiplicative")
s<-spectrum(ts, demean=T)


test<-stl(ts)

# messing asbout:
test<-stl.xts(t, s.window="periodic")

s<-spectrum(t$avg_SST_C, demean=F)

test<-fft(t)



plot(fft(t), type = "l")

test<-acf(t, demean=T)
s<-spectrum(t, demean=T)

```




## with ts whioch is  apin for 8 day observersations

```{r}
start<-min(x1$date)%>%as.POSIXct()
end<-max(x1$date)%>%as.POSIXct()

start<-c(20)

start<-min(x1$date)
end<-max(x1$date)


t<-x1%>%select(.,avg_CHL_mg_m3_day, avg_SST_C, avg_EF_mgC_m2_day ) %>% ts(.,start=start, end=end, deltat =(8/365) )

t<-x1%>%select(.,avg_EF_mgC_m2_day ) %>% ts(.,start=start, end=end, deltat =(7/365) )


t1<-decompose(t, type ="additive", filter=NULL)


```



# testing:
```{r}
print(ts(x1$avg_SST_C, frequency = 7), calendar = T)
```


## selct hurdat to match
```{r}
# adjust viraiable "distance"
# ef_200_st3.5<-full_join(x2, new.h, by="date")
ef_400_st3.5<-full_join(x2, new.h, by="date")


```

save

```{r}
setwd(wd)
setwd(output)
write.csv(ef_200_st3.5, "ef_200_st35.csv", row.names=FALSE)
write.csv(ef_400_st3.5, "ef_400_st35.csv", row.names=FALSE)

```


names()